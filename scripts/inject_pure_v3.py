
import json
import os
import re
from collections import defaultdict

# Mapping of Arabic Surah Names to Numbers for legacy parsing if needed
ARABIC_SURAH_MAP = {
    "Ø§Ù„ÙØ§ØªØ­Ø©": 1, "Ø§Ù„Ø¨Ù‚Ø±Ø©": 2, "Ø¢Ù„ Ø¹Ù…Ø±Ø§Ù†": 3, "Ø§Ù„Ù†Ø³Ø§Ø¡": 4, "Ø§Ù„Ù…Ø§Ø¦Ø¯Ø©": 5, "Ø§Ù„Ø£Ù†Ø¹Ø§Ù…": 6, "Ø§Ù„Ø£Ø¹Ø±Ø§Ù": 7, "Ø§Ù„Ø£Ù†ÙØ§Ù„": 8, "Ø§Ù„ØªÙˆØ¨Ø©": 9, "ÙŠÙˆÙ†Ø³": 10,
    "Ù‡ÙˆØ¯": 11, "ÙŠÙˆØ³Ù": 12, "Ø§Ù„Ø±Ø¹Ø¯": 13, "Ø§Ø¨Ø±Ø§Ù‡ÙŠÙ…": 14, "Ø¥Ø¨Ø±Ø§Ù‡ÙŠÙ…": 14, "Ø§Ù„Ø­Ø¬Ø±": 15, "Ø§Ù„Ù†Ø­Ù„": 16, "Ø§Ù„Ø¥Ø³Ø±Ø§Ø¡": 17, "Ø§Ù„ÙƒÙ‡Ù": 18, "Ù…Ø±ÙŠÙ…": 19, "Ø·Ù‡": 20,
    "Ø§Ù„Ø£Ù†Ø¨ÙŠØ§Ø¡": 21, "Ø§Ù„Ø­Ø¬": 22, "Ø§Ù„Ù…Ø¤Ù…Ù†ÙˆÙ†": 23, "Ø§Ù„Ù†ÙˆØ±": 24, "Ø§Ù„ÙØ±Ù‚Ø§Ù†": 25, "Ø§Ù„Ø´Ø¹Ø±Ø§Ø¡": 26, "Ø§Ù„Ù†Ù…Ù„": 27, "Ø§Ù„Ù‚ØµØµ": 28, "Ø§Ù„Ø¹Ù†ÙƒØ¨ÙˆØª": 29, "Ø§Ù„Ø±ÙˆÙ…": 30,
    "Ù„Ù‚Ù…Ø§Ù†": 31, "Ø§Ù„Ø³Ø¬Ø¯Ø©": 32, "Ø§Ù„Ø£Ø­Ø²Ø§Ø¨": 33, "Ø³Ø¨Ø£": 34, "ÙØ§Ø·Ø±": 35, "ÙŠØ³": 36, "Ø§Ù„ØµØ§ÙØ§Øª": 37, "Øµ": 38, "Ø§Ù„Ø²Ù…Ø±": 39, "ØºØ§ÙØ±": 40,
    "ÙØµÙ„Øª": 41, "Ø§Ù„Ø´ÙˆØ±Ù‰": 42, "Ø§Ù„Ø²Ø®Ø±Ù": 43, "Ø§Ù„Ø¯Ø®Ø§Ù†": 44, "Ø§Ù„Ø¬Ø§Ø«ÙŠØ©": 45, "Ø§Ù„Ø£Ø­Ù‚Ø§Ù": 46, "Ù…Ø­Ù…Ø¯": 47, "Ø§Ù„ÙØªØ­": 48, "Ø§Ù„Ø­Ø¬Ø±Ø§Øª": 49, "Ù‚": 50,
    "Ø§Ù„Ø°Ø§Ø±ÙŠØ§Øª": 51, "Ø§Ù„Ø·ÙˆØ±": 52, "Ø§Ù„Ù†Ø¬Ù…": 53, "Ø§Ù„Ù‚Ù…Ø±": 54, "Ø§Ù„Ø±Ø­Ù…Ù†": 55, "Ø§Ù„ÙˆØ§Ù‚Ø¹Ø©": 56, "Ø§Ù„Ø­Ø¯ÙŠØ¯": 57, "Ø§Ù„Ù…Ø¬Ø§Ø¯Ù„Ø©": 58, "Ø§Ù„Ø­Ø´Ø±": 59, "Ø§Ù„Ù…Ù…ØªØ­Ù†Ø©": 60,
    "Ø§Ù„ØµÙ": 61, "Ø§Ù„Ø¬Ù…Ø¹Ø©": 62, "Ø§Ù„Ù…Ù†Ø§ÙÙ‚ÙˆÙ†": 63, "Ø§Ù„ØªØºØ§Ø¨Ù†": 64, "Ø§Ù„Ø·Ù„Ø§Ù‚": 65, "Ø§Ù„ØªØ­Ø±ÙŠÙ…": 66, "Ø§Ù„Ù…Ù„Ùƒ": 67, "Ø§Ù„Ù‚Ù„Ù…": 68, "Ø§Ù„Ø­Ø§Ù‚Ø©": 69, "Ø§Ù„Ù…Ø¹Ø§Ø±Ø¬": 70,
    "Ù†ÙˆØ­": 71, "Ø§Ù„Ø¬Ù†": 72, "Ø§Ù„Ù…Ø²Ù…Ù„": 73, "Ø§Ù„Ù…Ø¯Ø«Ø±": 74, "Ø§Ù„Ù‚ÙŠØ§Ù…Ø©": 75, "Ø§Ù„Ø§Ù†Ø³Ø§Ù†": 76, "Ø§Ù„Ø¥Ù†Ø³Ø§Ù†": 76, "Ø§Ù„Ù…Ø±Ø³Ù„Ø§Øª": 77, "Ø§Ù„Ù†Ø¨Ø£": 78, "Ø§Ù„Ù†Ø§Ø²Ø¹Ø§Øª": 79, "Ø¹Ø¨Ø³": 80,
    "Ø§Ù„ØªÙƒÙˆÙŠØ±": 81, "Ø§Ù„Ø§Ù†ÙØ·Ø§Ø±": 82, "Ø§Ù„Ù…Ø·ÙÙÙŠÙ†": 83, "Ø§Ù„Ø§Ù†Ø´Ù‚Ø§Ù‚": 84, "Ø§Ù„Ø¨Ø±ÙˆØ¬": 85, "Ø§Ù„Ø·Ø§Ø±Ù‚": 86, "Ø§Ù„Ø£Ø¹Ù„Ù‰": 87, "Ø§Ù„ØºØ§Ø´ÙŠØ©": 88, "Ø§Ù„ÙØ¬Ø±": 89, "Ø§Ù„Ø¨Ù„Ø¯": 90,
    "Ø§Ù„Ø´Ù…Ø³": 91, "Ø§Ù„Ù„ÙŠÙ„": 92, "Ø§Ù„Ø¶Ø­Ù‰": 93, "Ø§Ù„Ø´Ø±Ø­": 94, "Ø§Ù„ØªÙŠÙ†": 95, "Ø§Ù„Ø¹Ù„Ù‚": 96, "Ø§Ù„Ù‚Ø¯Ø±": 97, "Ø§Ù„Ø¨ÙŠÙ†Ø©": 98, "Ø§Ù„Ø²Ù„Ø²Ù„Ø©": 99, "Ø§Ù„Ø¹Ø§Ø¯ÙŠØ§Øª": 100,
    "Ø§Ù„Ù‚Ø§Ø±Ø¹Ø©": 101, "Ø§Ù„ØªÙƒØ§Ø«Ø±": 102, "Ø§Ù„Ø¹ØµØ±": 103, "Ø§Ù„Ù‡Ù…Ø²Ø©": 104, "Ø§Ù„ÙÙŠÙ„": 105, "Ù‚Ø±ÙŠØ´": 106, "Ø§Ù„Ù…Ø§Ø¹ÙˆÙ†": 107, "Ø§Ù„ÙƒÙˆØ«Ø±": 108, "Ø§Ù„ÙƒØ§ÙØ±ÙˆÙ†": 109, "Ø§Ù„Ù†ØµØ±": 110,
    "Ø§Ù„Ù…Ø³Ø¯": 111, "Ø§Ù„Ø§Ø®Ù„Ø§Øµ": 112, "Ø§Ù„Ø¥Ø®Ù„Ø§Øµ": 112, "Ø§Ù„ÙÙ„Ù‚": 113, "Ø§Ù„Ù†Ø§Ø³": 114
}

DEEPSEEK_V3_RESULTS = '/home/absolut7/Documents/ihyalovesecond/deepseek_analysis_results.jsonl'
BOOK_META_FILE = '/home/absolut7/Documents/ihya_love/book_metadata.json'
SURAH_DATA_DIR = '/home/absolut7/Documents/ihyatafsirwebsite_2/quranwbw/surahs/data'
BOOKS_DIR = '/home/absolut7/Documents/ihyatafsirwebsite_2/quranwbw/books'

def normalize_filename(filename):
    """Normalize 'vol1_Vol1-book-9.doc.txt' to 'Vol1-book-9.doc'"""
    if not filename: return ""
    base = filename.split('_')[-1]
    if base.endswith('.txt'): base = base[:-4]
    return base

def find_book_file(book_source_raw):
    clean_src = book_source_raw.replace('.doc', '')
    if not os.path.exists(BOOKS_DIR): return None
    for fname in os.listdir(BOOKS_DIR):
        if clean_src in fname: return fname
    return None

def main():
    print(f"Loading Pure V3 Results from {DEEPSEEK_V3_RESULTS}...")
    
    # Load Metadata
    book_meta = {}
    if os.path.exists(BOOK_META_FILE):
        with open(BOOK_META_FILE, 'r') as f:
            book_meta = json.load(f)

    verse_map = defaultdict(list)
    results_count = 0
    tafsir_count = 0
    
    with open(DEEPSEEK_V3_RESULTS, 'r') as f:
        for line in f:
            try:
                res = json.loads(line)
                results_count += 1
                if res['status'] == 'success' and res['analysis']['analysis_type'] == 'tafsir':
                    tafsir_count += 1
                    vk = res['custom_id']
                    # Parse vk (e.g., "73:7")
                    if ':' in vk:
                        s_part, a_part = vk.split(':')
                        s_num = int(s_part)
                        # Handle range like "39-40"
                        if '-' in a_part:
                            a_num = int(a_part.split('-')[0])
                        else:
                            a_num = int(a_part)
                        
                        verse_map[(s_num, a_num)].append({
                            'arabic': res['analysis']['arabic_snippet'],
                            'english': res['analysis']['english_text'],
                            'file': res.get('file', '')
                        })
            except Exception as e:
                pass

    print(f"Found {tafsir_count} pure tafsir entries for {len(verse_map)} unique verses.")

    # Reset Website Data (Clear old injections)
    print("Clearing old Ihya commentaries and injecting Pure V3...")
    for s_num in range(1, 115):
        json_path = os.path.join(SURAH_DATA_DIR, f"{s_num}.json")
        if not os.path.exists(json_path): continue
        
        with open(json_path, 'r', encoding='utf-8') as f:
            surah_data = json.load(f)
        
        modified = False
        for ayah_key in list(surah_data.keys()):
            if not ayah_key.isdigit(): continue
            ayah_num = int(ayah_key)
            
            # ALWAYS clear existing 'ihya' field to ensure purity
            if 'a' in surah_data[ayah_key] and 'ihya' in surah_data[ayah_key]['a']:
                del surah_data[ayah_key]['a']['ihya']
                modified = True
            
            target_key = (s_num, ayah_num)
            if target_key in verse_map:
                comms = verse_map[target_key]
                
                html_parts = []
                html_parts.append("<div class='ihya-container' style='margin-top: 20px; padding: 15px; background-color: #fcfaf2; border-left: 4px solid #d4af37; border-radius: 4px; box-shadow: 0 2px 5px rgba(0,0,0,0.05);'>")
                html_parts.append("<h4 style='color: #d4af37; margin-bottom: 15px; font-family: \"Cinzel\", serif; font-size: 1.2em;'>Ihya 'Ulum al-Din <span style='font-size: 0.8em; color: #888;'>(Verbatim V3)</span></h4>")
                
                for idx, c in enumerate(comms):
                    file_norm = normalize_filename(c['file'])
                    book_display = file_norm.replace('.doc', '').replace('-', ' ')
                    
                    # Metadata lookup
                    meta_key = next((k for k in book_meta if file_norm in k), None)
                    if meta_key:
                        info = book_meta[meta_key]
                        book_display = info.get('english_title', book_display)
                        vol = info.get('vol', '')
                        if vol: book_display = f"Vol {vol}: {book_display}"
                    
                    book_file = find_book_file(file_norm)
                    book_link = f"../books/{book_file}" if book_file else "#"

                    if idx > 0:
                        html_parts.append("<hr style='border-top: 1px dashed #e0d0a0; margin: 20px 0;'>")

                    html_parts.append("<div class='ihya-entry'>")
                    html_parts.append(f"<div style='margin-bottom: 12px;'>")
                    html_parts.append(f"<a href='{book_link}' target='_blank' class='badge' style='background-color: #f4ecd8; color: #8a6d3b; border: 1px solid #d0c090; padding: 5px 10px; font-weight: 500;'>ğŸ“– {book_display}</a>")
                    html_parts.append("</div>")
                    
                    html_parts.append(f"<div class='ihya-text' style='font-size: 1.15em; line-height: 1.7; color: #2c3e50; margin-bottom: 12px; font-family: \"Georgia\", serif;'>{c['english']}</div>")
                    html_parts.append(f"<div class='ihya-arabic' style='font-size: 1.35em; line-height: 2; color: #1a1a1a; text-align: right; direction: rtl; font-family: \"Traditional Arabic\", \"Noorehuda\", serif; background: #fff; padding: 15px; border-radius: 6px; border: 1px solid #e8e0c8;'>{c['arabic']}</div>")
                    html_parts.append("</div>")

                html_parts.append("</div>")
                
                if 'a' not in surah_data[ayah_key]: surah_data[ayah_key]['a'] = {}
                surah_data[ayah_key]['a']['ihya'] = "".join(html_parts)
                modified = True

        if modified:
            with open(json_path, 'w', encoding='utf-8') as f:
                json.dump(surah_data, f, ensure_ascii=False, separators=(',', ':'))

    print("Website updated with Pure V3 data.")

if __name__ == "__main__":
    main()
